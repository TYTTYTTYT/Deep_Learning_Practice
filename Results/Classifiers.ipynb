{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from torch import nn\n","import torch.nn.functional as F\n","import torch\n","from torch import optim\n","import random\n","import time\n","from utils import load_1d_data\n","from utils import load_2d_data\n","from utils import draw\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def sigmoid(z):\n","    return 1.0 / (1.0 + np.exp(-z))\n","\n","def d_sigmoid(z):\n","    return sigmoid(z) * (1 - sigmoid(z))\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class Network_NP:\n","\n","    __batch_size__ = 0\n","\n","    def __init__(self, sizes):\n","        self.num_layers = len(sizes)\n","        self.sizes = sizes\n","        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n","        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n","\n","    def feedforward(self, a):\n","        for w, b in zip(self.weights, self.biases):\n","            a = sigmoid(w @ a + b)\n","        return a\n","\n","    def predict(self, x):\n","        y = self.feedforward(x)\n","        return np.argmax(y)\n","\n","    def SGD(self, train_data, epoch, batch_size, eta, test_data=None):\n","        n = len(train_data)\n","        self.__batch_size__ = batch_size\n","\n","        for i in range(epoch):\n","            tic = time.time()\n","\n","            random.shuffle(train_data)\n","            for j in range(0, n, batch_size):\n","                batch = train_data[j: j + batch_size]\n","                self.update_batch(batch, eta)\n","\n","            if test_data:\n","                self.evaluate(test_data)\n","            \n","            elapse = time.time() - tic\n","            print('epoch ' + str(i) + 'finished!')\n","            print('time usage: ' + str(elapse))\n","        \n","        return\n","\n","    def update_batch(self, batch, eta):\n","        delta_w = [np.zeros(w.shape) for w in self.weights]\n","        delta_b = [np.zeros(b.shape) for b in self.biases]\n","\n","        for x, y in batch:\n","            d_w, d_b = self.bp(x, y)\n","            delta_w = [origin + new for origin, new in zip(delta_w, d_w)]\n","            delta_b = [origin + new for origin, new in zip(delta_b, d_b)]\n","\n","        self.weights = [w - eta / len(batch) * d for w, d in zip(self.weights, delta_w)]\n","        self.biases = [b - eta / len(batch) * d for b, d in zip(self.biases, delta_b)]\n","        \n","        return\n","\n","    def bp(self, x, y):\n","        d_ws = [np.empty(w.shape) for w in self.weights]\n","        d_bs = [np.empty(b.shape) for b in self.biases]\n","        a = x\n","        activations = [x]\n","        zs = []\n","\n","        for w, b in zip(self.weights, self.biases):\n","            z = w @ a\n","            z = z + b\n","            a = sigmoid(z)\n","            activations.append(a)\n","            zs.append(z)\n","        \n","        d_cost = a - y\n","        delta = d_cost * d_sigmoid(zs[-1])\n","        d_bs[-1] = delta\n","        d_ws[-1] = d_bs[-1] @ activations[-2].T\n","\n","        for l in range(2, self.num_layers):\n","            delta = d_sigmoid(zs[-l]) * self.weights[-l + 1].T @ delta\n","            d_ws[-l] = delta @ activations[-l - 1].T\n","            d_bs[-l] = delta\n","        \n","        return d_ws, d_bs\n","\n","    def evaluate(self, test_data):\n","        n = len(test_data)\n","        correct = 0\n","        wrong = 0\n","        for x, y in test_data:\n","            if self.predict(x) == np.argmax(y):\n","                correct += 1\n","            else:\n","                wrong += 1\n","        print('accuracy = ' + str(correct / (correct + wrong)))\n","        return\n","\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class Network_torch:\n","\n","    def __init__(self, sizes):\n","        self.sizes = sizes\n","        self.num_layers = len(sizes)\n","\n","        if torch.cuda.is_available():\n","            self.device = torch.device(\"cuda\")\n","        else:\n","            self.device = torch.device(\"cpu\")\n","        \n","        self.weights = [torch.randn((n, d), dtype=torch.double)\n","                        for n, d in zip(self.sizes[1:], self.sizes[:-1])]\n","        self.biases = [torch.randn((n, 1), dtype=torch.double)\n","                       for n in sizes[1:]]\n","\n","    def feedforward(self, x):\n","        activation = x\n","        for w, b in zip(self.weights, self.biases):\n","            activation = (w @ activation + b).sigmoid()\n","        \n","        return activation\n","\n","    def predict(self, x):\n","        with torch.no_grad():\n","            activation = self.feedforward(x)\n","            values, indices = torch.max(activation, dim=0)\n","\n","        return indices\n","\n","    def featurelize(self, labels):\n","        n = len(labels)\n","        features = torch.zeros(self.sizes[-1], n, device=self.device, dtype=torch.double)\n","\n","        for i in range(n):\n","            features[labels[i], i] = 1\n","\n","        return features\n","\n","    def evaluate(self, test_set, test_label):\n","        with torch.no_grad():\n","            test_set = torch.from_numpy(test_set.T).to(self.weights[0].device)\n","            test_label = torch.from_numpy(test_label).to(self.weights[0].device)\n","\n","            prediction = self.predict(test_set)\n","            comp = prediction == test_label\n","\n","            accuracy = comp.sum().double() / comp.shape[0]\n","            accuracy = accuracy.cpu().data.tolist()\n","\n","            print('accuracy: ' + str(accuracy))\n","\n","            return accuracy\n","\n","    def MSE(self, activations, y):\n","        d = y - activations\n","        cost = d.square().sum() / activations.shape[1] / 2\n","\n","        return cost\n","\n","    def cross_entropy(self, activations, y):\n","        cost = -(y * activations.log() + (1 - y) * (1 - activations).log()).sum() / activations.shape[1]\n","        return cost\n","\n","    def SGD(self, train_set, train_label, epoch, batch_size, eta,\n","            test_set=None, test_label=None, cost_function=None):\n","        if cost_function == 'MSE':\n","            cost_function = self.MSE\n","        if cost_function == 'cross_entropy':\n","            cost_function = self.cross_entropy\n","        else:\n","            cost_function = self.cross_entropy\n","\n","        n = train_set.shape[0]\n","        for i in range(self.num_layers - 1):\n","            self.weights[i] = self.weights[i].to(self.device)\n","            self.weights[i].requires_grad_()\n","            self.biases[i] = self.biases[i].to(self.device)\n","            self.biases[i].requires_grad_()\n","        \n","        train_set = torch.from_numpy(train_set.T).to(self.device)\n","        train_label = self.featurelize(train_label).to(self.device)\n","\n","        for i in range(epoch):\n","            tic = time.time()\n","\n","            perm = torch.randperm(n)\n","\n","            for j in range(0, n, batch_size):\n","                indices = perm[j:j + batch_size]\n","\n","                activations = self.feedforward(train_set[:, indices])\n","                # d = train_label[:, indices] - activations\n","                # cost = (d.square()).sum() / batch_size / 2\n","                cost = cost_function(activations, train_label[:, indices])\n","                cost.backward()\n","\n","                for k in range(self.num_layers - 1):\n","                    self.weights[k] = (self.weights[k] - eta * self.weights[k].grad).detach()\n","                    self.weights[k].requires_grad_()\n","                    self.biases[k] = (self.biases[k] - eta * self.biases[k].grad).detach()\n","                    self.biases[k].requires_grad_()\n","            \n","            if test_set is not None:\n","                self.evaluate(test_set, test_label)\n","\n","            elapse = time.time() - tic\n","            print('epoch ' + str(i) + ' finished!')\n","            print('time usage: ' + str(elapse))\n","\n","        for i in range(self.num_layers - 1):\n","            self.weights[i] = self.weights[i].to(torch.device('cpu')).detach()\n","            self.biases[i] = self.biases[i].to(torch.device('cpu')).detach()\n","        return\n",""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class CNN_torch(nn.Module):\n","\n","    def __init__(self):\n","        super(CNN_torch, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 6, 3, stride=(1, 1))\n","        self.conv2 = nn.Conv2d(6, 16, 3, stride=(1, 1))\n","\n","        self.pool = nn.MaxPool2d(2, 2)\n","        \n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","        self.sm = nn.Softmax()\n","\n","        self.criterion = nn.NLLLoss()\n","\n","        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","        return\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","\n","        x = self.pool(F.relu(self.conv2(x)))\n","\n","        x = x.view(-1, self.num_flat_features(x))   # -1 represents the batch dimension\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.sm(self.fc3(x))\n","        return x\n","\n","    def predict(self, x):\n","        with torch.no_grad():\n","            activation = self.forward(x)\n","            values, indices = torch.max(activation, dim=1)\n","\n","        return indices\n","\n","    def evaluate(self, valid_set, valid_label):\n","        with torch.no_grad():\n","            prediction = self.predict(valid_set)\n","            comp = prediction == valid_label\n","\n","            accuracy = comp.sum().double() / comp.shape[0]\n","            accuracy = accuracy.cpu().data.tolist()\n","\n","            print('CNN\\'s accuracy: ' + str(accuracy))\n","\n","            return accuracy\n","\n","    def SGD(self, train_set, train_label, batch_size, num_epoche, eta, momentum,\n","            valid_set=None, valid_label=None):\n","        self.to(self.device)\n","        train_set = train_set.to(self.device)\n","        train_label = train_label.to(self.device)\n","\n","        optimizer = optim.SGD(self.parameters(), lr=eta, momentum=momentum)\n","        num_set = train_set.size()[0]\n","        \n","        for epoch in range(num_epoche):\n","            tic = time.time()\n","\n","            perm = perm = torch.randperm(num_set)\n","            for j in range(0, num_set, batch_size):\n","                indices = perm[j:j + batch_size]\n","\n","                optimizer.zero_grad()\n","                out = self.forward(train_set[indices])\n","                loss = self.criterion(out, train_label[indices])\n","                loss.backward()\n","                optimizer.step()\n","\n","            elapse = time.time() - tic\n","            print('epoch ' + str(epoch) + ' finished!')\n","            print('time usage: ' + str(elapse))\n","            \n","            if valid_set is not None and valid_label is not None:\n","                valid_set = valid_set.to(self.device)\n","                valid_label = valid_label.to(self.device)\n","                self.evaluate(valid_set, valid_label)\n","        \n","        self.to(torch.device('cpu'))\n","\n","    def num_flat_features(self, x):\n","        size = x.size()[1:]\n","        num_features = 1\n","        for s in size:\n","            num_features *= s\n","        return num_features\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["(train_set, train_label, valid_set, valid_label, test_set, test_label), train_data, valid_data = load_1d_data(\n","    30000,\n","    500,\n","    1000)\n","train_set_2d, train_label_2d, valid_set_2d, valid_label_2d, test_set_2d, test_label_2d = load_2d_data(30000, 500, 1000)\n","\n",""]},{"cell_type":"code","execution_count":7,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"accuracy: 0.7020000000000001\nepoch 0 finished!\ntime usage: 6.78835391998291\naccuracy: 0.8300000000000001\nepoch 1 finished!\ntime usage: 6.572842836380005\naccuracy: 0.878\nepoch 2 finished!\ntime usage: 6.678527116775513\naccuracy: 0.902\nepoch 3 finished!\ntime usage: 6.622081518173218\naccuracy: 0.894\nepoch 4 finished!\ntime usage: 6.5622193813323975\naccuracy: 0.908\nepoch 5 finished!\ntime usage: 6.881671905517578\naccuracy: 0.926\nepoch 6 finished!\ntime usage: 6.756439447402954\naccuracy: 0.914\nepoch 7 finished!\ntime usage: 6.614870548248291\naccuracy: 0.934\nepoch 8 finished!\ntime usage: 6.743257522583008\naccuracy: 0.926\nepoch 9 finished!\ntime usage: 6.556797504425049\naccuracy: 0.922\nepoch 10 finished!\ntime usage: 6.77974009513855\naccuracy: 0.936\nepoch 11 finished!\ntime usage: 6.7851221561431885\naccuracy: 0.934\nepoch 12 finished!\ntime usage: 6.729641675949097\naccuracy: 0.928\nepoch 13 finished!\ntime usage: 7.02612566947937\naccuracy: 0.9440000000000001\nepoch 14 finished!\ntime usage: 7.0052900314331055\naccuracy: 0.932\nepoch 15 finished!\ntime usage: 6.649183750152588\naccuracy: 0.932\nepoch 16 finished!\ntime usage: 6.522594451904297\naccuracy: 0.9460000000000001\nepoch 17 finished!\ntime usage: 6.4876275062561035\naccuracy: 0.9440000000000001\nepoch 18 finished!\ntime usage: 6.783648252487183\naccuracy: 0.9380000000000001\nepoch 19 finished!\ntime usage: 6.428816318511963\naccuracy: 0.934\nepoch 20 finished!\ntime usage: 6.625903844833374\naccuracy: 0.9460000000000001\nepoch 21 finished!\ntime usage: 6.453148365020752\naccuracy: 0.9380000000000001\nepoch 22 finished!\ntime usage: 6.64808464050293\naccuracy: 0.9440000000000001\nepoch 23 finished!\ntime usage: 6.573514461517334\naccuracy: 0.9400000000000001\nepoch 24 finished!\ntime usage: 6.561791658401489\naccuracy: 0.9400000000000001\nepoch 25 finished!\ntime usage: 6.5239832401275635\naccuracy: 0.9420000000000001\nepoch 26 finished!\ntime usage: 6.551545143127441\naccuracy: 0.9440000000000001\nepoch 27 finished!\ntime usage: 6.488118648529053\naccuracy: 0.9420000000000001\nepoch 28 finished!\ntime usage: 6.486187219619751\naccuracy: 0.9400000000000001\nepoch 29 finished!\ntime usage: 6.4865968227386475\n"}],"source":["net = Network_torch([784, 1000, 100, 30, 30, 30, 10])\n","net.SGD(train_set, train_label, 30, 10, 0.1, valid_set, valid_label)\n",""]},{"cell_type":"code","execution_count":8,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"accuracy = 0.886\nepoch 0finished!\ntime usage: 5.829579591751099\naccuracy = 0.906\nepoch 1finished!\ntime usage: 5.77797532081604\naccuracy = 0.93\nepoch 2finished!\ntime usage: 5.8031628131866455\naccuracy = 0.932\nepoch 3finished!\ntime usage: 5.895583629608154\naccuracy = 0.93\nepoch 4finished!\ntime usage: 5.905006170272827\naccuracy = 0.944\nepoch 5finished!\ntime usage: 5.900408983230591\naccuracy = 0.946\nepoch 6finished!\ntime usage: 5.856336355209351\naccuracy = 0.942\nepoch 7finished!\ntime usage: 5.912381172180176\naccuracy = 0.95\nepoch 8finished!\ntime usage: 5.901386022567749\naccuracy = 0.954\nepoch 9finished!\ntime usage: 5.912071228027344\naccuracy = 0.944\nepoch 10finished!\ntime usage: 5.905231714248657\naccuracy = 0.948\nepoch 11finished!\ntime usage: 5.893282175064087\naccuracy = 0.954\nepoch 12finished!\ntime usage: 5.8909406661987305\naccuracy = 0.952\nepoch 13finished!\ntime usage: 5.907840013504028\naccuracy = 0.95\nepoch 14finished!\ntime usage: 6.052498817443848\naccuracy = 0.96\nepoch 15finished!\ntime usage: 5.873851776123047\naccuracy = 0.966\nepoch 16finished!\ntime usage: 6.025371551513672\naccuracy = 0.952\nepoch 17finished!\ntime usage: 6.036120653152466\naccuracy = 0.956\nepoch 18finished!\ntime usage: 6.041666030883789\naccuracy = 0.964\nepoch 19finished!\ntime usage: 6.063845872879028\naccuracy = 0.96\nepoch 20finished!\ntime usage: 6.0352184772491455\naccuracy = 0.954\nepoch 21finished!\ntime usage: 6.0862908363342285\naccuracy = 0.964\nepoch 22finished!\ntime usage: 6.004288673400879\naccuracy = 0.954\nepoch 23finished!\ntime usage: 6.045671463012695\naccuracy = 0.958\nepoch 24finished!\ntime usage: 5.903057813644409\naccuracy = 0.956\nepoch 25finished!\ntime usage: 5.858776092529297\naccuracy = 0.96\nepoch 26finished!\ntime usage: 5.881867408752441\naccuracy = 0.954\nepoch 27finished!\ntime usage: 5.945671081542969\naccuracy = 0.958\nepoch 28finished!\ntime usage: 5.880879878997803\naccuracy = 0.952\nepoch 29finished!\ntime usage: 5.84468936920166\n"}],"source":["net = Network_NP([784, 100, 30, 10])\n","net.SGD(train_data, 30, 10, 3, valid_data)\n",""]},{"cell_type":"code","execution_count":9,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"epoch 0 finished!\ntime usage: 4.660363674163818\nCNN's accuracy: 0.6940000000000001\nepoch 1 finished!\ntime usage: 4.65527868270874\nCNN's accuracy: 0.788\nepoch 2 finished!\ntime usage: 4.814701080322266\nCNN's accuracy: 0.936\nepoch 3 finished!\ntime usage: 4.719542503356934\nCNN's accuracy: 0.9560000000000001\nepoch 4 finished!\ntime usage: 4.537584543228149\nCNN's accuracy: 0.982\nepoch 5 finished!\ntime usage: 4.798503160476685\nCNN's accuracy: 0.97\nepoch 6 finished!\ntime usage: 4.608574151992798\nCNN's accuracy: 0.98\nepoch 7 finished!\ntime usage: 4.481205224990845\nCNN's accuracy: 0.98\nepoch 8 finished!\ntime usage: 4.6471052169799805\nCNN's accuracy: 0.98\nepoch 9 finished!\ntime usage: 4.7121171951293945\nCNN's accuracy: 0.97\nepoch 10 finished!\ntime usage: 4.708117961883545\nCNN's accuracy: 0.978\nepoch 11 finished!\ntime usage: 4.463668346405029\nCNN's accuracy: 0.966\nepoch 12 finished!\ntime usage: 4.503969192504883\nCNN's accuracy: 0.96\nepoch 13 finished!\ntime usage: 4.483353614807129\nCNN's accuracy: 0.97\nepoch 14 finished!\ntime usage: 4.517721652984619\nCNN's accuracy: 0.9500000000000001\nepoch 15 finished!\ntime usage: 4.548443078994751\nCNN's accuracy: 0.978\nepoch 16 finished!\ntime usage: 4.529623031616211\nCNN's accuracy: 0.9540000000000001\nepoch 17 finished!\ntime usage: 4.483777284622192\nCNN's accuracy: 0.9500000000000001\nepoch 18 finished!\ntime usage: 4.618110418319702\nCNN's accuracy: 0.9460000000000001\nepoch 19 finished!\ntime usage: 4.583485126495361\nCNN's accuracy: 0.47400000000000003\n"}],"source":["net = CNN_torch()\n","net.SGD(train_set_2d, train_label_2d, 10, 20, 0.1, 0.0, valid_set_2d, valid_label_2d)\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}